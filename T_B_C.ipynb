{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeM9203/DAEN-429-Final-Project/blob/main/T_B_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KpzCUErSsVN"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
        "\n",
        "print(path)\n",
        "\n",
        "# /kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import re\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 429\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "LKVsh9idpDFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading (Stratified Split)"
      ],
      "metadata": {
        "id": "NdkOf0kj-j9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Data Configuration\n",
        "# --------------------------\n",
        "DATA_DIR = '/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\n",
        "BATCH_SIZE = 64\n",
        "IMG_SIZE = 224\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Custom Transform\n",
        "# --------------------------\n",
        "def custom_to_tensor(pic):\n",
        "    img = np.array(pic, dtype=np.float32)\n",
        "    img = img / 255.0\n",
        "    img = img.transpose((2, 0, 1))\n",
        "    return torch.tensor(img)\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Transforms\n",
        "# --------------------------\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),        # Keep images consistent\n",
        "\n",
        "        transforms.RandomHorizontalFlip(p=0.1),         # Very small chance (ASL hand signs are NOT always left-right symmetric)\n",
        "        transforms.RandomRotation(5),                    # Max 5 degrees keeps gestures valid\n",
        "        transforms.ColorJitter(brightness=0.1,\n",
        "                               contrast=0.1,\n",
        "                               saturation=0.1,\n",
        "                               hue=0.02),               # Subtle lighting variation\n",
        "        transforms.Lambda(custom_to_tensor),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.Lambda(custom_to_tensor),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Helper: Transformed Subset\n",
        "# --------------------------\n",
        "class TransformedSubset(torch.utils.data.Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.subset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Load Full Dataset\n",
        "# --------------------------\n",
        "full_dataset_raw = datasets.ImageFolder(root=DATA_DIR)\n",
        "classes = full_dataset_raw.classes\n",
        "print(f\"Classes ({len(classes)}): {classes}\")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# REQUIRED: Stratified 80/20 Split (seed = 429)\n",
        "# --------------------------\n",
        "indices = np.arange(len(full_dataset_raw))\n",
        "labels = np.array([label for _, label in full_dataset_raw.samples])\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    indices,\n",
        "    test_size=0.2,\n",
        "    stratify=labels,\n",
        "    random_state=429\n",
        ")\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Create Transformed Subsets\n",
        "# --------------------------\n",
        "train_dataset = TransformedSubset(Subset(full_dataset_raw, train_idx),\n",
        "                                  data_transforms['train'])\n",
        "val_dataset = TransformedSubset(Subset(full_dataset_raw, val_idx),\n",
        "                                data_transforms['val'])\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# DataLoaders\n",
        "# --------------------------\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
        "                        shuffle=False, num_workers=0)\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Val samples: {len(val_dataset)}\")\n"
      ],
      "metadata": {
        "id": "kQwtMylMpdQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_indices = set(train_idx)\n",
        "val_set_indices = set(val_idx)\n",
        "\n",
        "overlap = train_set_indices.intersection(val_set_indices)\n",
        "print(\"Overlap size:\", len(overlap))"
      ],
      "metadata": {
        "id": "JZ0aelgtsqqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition (T-B: Last Block)"
      ],
      "metadata": {
        "id": "220pV8M0-pmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tb_model(num_classes):\n",
        "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.layer4.parameters():\n",
        "        param.requires_grad = True\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "model = get_tb_model(len(classes))\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"Trainable parameters:\")\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "metadata": {
        "id": "BT4j8txGqLKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "THltlddZ-tRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(preds, labels):\n",
        "    preds = np.array(preds)\n",
        "    labels = np.array(labels)\n",
        "    acc = np.mean(preds == labels)\n",
        "    unique_labels = np.unique(np.concatenate([preds, labels]))\n",
        "    f1_scores = []\n",
        "    for l in unique_labels:\n",
        "        tp = np.sum((preds == l) & (labels == l))\n",
        "        fp = np.sum((preds == l) & (labels != l))\n",
        "        fn = np.sum((preds != l) & (labels == l))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        if precision + recall > 0:\n",
        "            f1 = 2 * (precision * recall) / (precision + recall)\n",
        "        else:\n",
        "            f1 = 0\n",
        "        f1_scores.append(f1)\n",
        "    macro_f1 = np.mean(f1_scores) if f1_scores else 0\n",
        "    return acc, macro_f1\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3):\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "    val_acc_history = []\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "        model.train()\n",
        "\n",
        "            # ðŸ”’ Freeze all BatchNorm running stats for layers you froze\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                if not any(p.requires_grad for p in m.parameters()):\n",
        "                    m.eval()\n",
        "                    m.track_running_stats = False\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print(f'   Batch {i+1}/{len(train_loader)} - Loss: {loss.item():.4f}')\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "        train_loss_history.append(epoch_loss)\n",
        "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_corrects = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                val_corrects += torch.sum(preds == labels.data)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
        "        epoch_val_acc = val_corrects.double() / len(val_loader.dataset)\n",
        "        _, epoch_f1 = calculate_metrics(all_preds, all_labels)\n",
        "        val_loss_history.append(epoch_val_loss)\n",
        "        val_acc_history.append(epoch_val_acc)\n",
        "        print(f'Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f} F1: {epoch_f1:.4f}')\n",
        "\n",
        "        if epoch_f1 > best_f1:\n",
        "            best_f1 = epoch_f1\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            print(f\"   >> New Best F1: {best_f1:.4f} <<\")\n",
        "\n",
        "\n",
        "\n",
        "    print(f'Best Val F1: {best_f1:.4f}')\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_loss_history, val_loss_history, best_f1\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
        "\n",
        "print(\"Starting T-B Training...\")\n",
        "trained_model, train_loss, val_loss, tb_best_f1 = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3)"
      ],
      "metadata": {
        "id": "NKz12sWEqOCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in model.modules():\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        print(m, [p.requires_grad for p in m.parameters()])\n"
      ],
      "metadata": {
        "id": "kbkDYG9kzQSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CHECKING\n",
        "\n",
        "bn_running_means_before = []\n",
        "bn_running_vars_before = []\n",
        "\n",
        "for m in model.modules():\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        bn_running_means_before.append(m.running_mean.clone())\n",
        "        bn_running_vars_before.append(m.running_var.clone())\n",
        "\n",
        "# Run ONE training batch\n",
        "imgs, labels = next(iter(train_loader))\n",
        "imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "model.train()\n",
        "optimizer.zero_grad()\n",
        "outputs = model(imgs)\n",
        "loss = criterion(outputs, labels)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "bn_running_means_after = []\n",
        "bn_running_vars_after = []\n",
        "\n",
        "for m in model.modules():\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        bn_running_means_after.append(m.running_mean.clone())\n",
        "        bn_running_vars_after.append(m.running_var.clone())\n",
        "\n",
        "# Compare\n",
        "changed = False\n",
        "for b1, b2 in zip(bn_running_means_before, bn_running_means_after):\n",
        "    if not torch.equal(b1, b2):\n",
        "        changed = True\n",
        "\n",
        "print(\"BatchNorm running stats changed:\", changed)"
      ],
      "metadata": {
        "id": "lw_C4KNqxNcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(val_loss, label='Val Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I9RCwdm2qqQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (T-C) Progressive Unfreezing\n",
        "\n",
        "This section implements **T-C: Progressive**.\n",
        "- **Policy**: Start from T-B's best checkpoint; unfreeze layer3 as well; train layer3 + layer4 + head (fc).\n",
        "\n"
      ],
      "metadata": {
        "id": "idN-Jll19oGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# (T-C) Progressive Unfreezing\n",
        "# -----------------------------\n",
        "print(\"Setting up T-C...\")\n",
        "\n",
        "# 1. Freeze entire model\n",
        "for param in trained_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 2. Unfreeze layer3, layer4, and fc\n",
        "for param in trained_model.layer3.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in trained_model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in trained_model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(\"\\nTrainable parameters (T-C):\")\n",
        "for name, param in trained_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(\"  \", name)\n",
        "\n",
        "# 3. Optimizer for the newly unfrozen layers\n",
        "optimizer_tc = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, trained_model.parameters()),\n",
        "    lr=5e-5\n",
        ")\n",
        "\n",
        "# 4. Train T-C (Progressive Unfreezing)\n",
        "print(\"\\nStarting T-C Training...\")\n",
        "trained_model_tc, train_loss_tc, val_loss_tc, tc_best_f1 = train_model(\n",
        "    trained_model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer_tc,\n",
        "    num_epochs=3\n",
        ")\n",
        "\n",
        "# 5. Plot loss curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss_tc, label='Train Loss (T-C)')\n",
        "plt.plot(val_loss_tc, label='Val Loss (T-C)')\n",
        "plt.title('T-C: Progressive Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Best T-C F1:\", tc_best_f1)\n"
      ],
      "metadata": {
        "id": "wm60k7cR9oui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, p in trained_model.named_parameters():\n",
        "    print(name, p.requires_grad)\n"
      ],
      "metadata": {
        "id": "Pvx5GcSY7-ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*30)\n",
        "print(\"FINAL RESULTS\")\n",
        "print(\"=\"*30)\n",
        "print(f\"T-B (Last Block) Best F1: {tb_best_f1:.4f}\")\n",
        "print(f\"T-C (Progressive) Best F1: {tc_best_f1:.4f}\")\n",
        "print(\"-\"*30)\n",
        "if tc_best_f1 > tb_best_f1:\n",
        "    print(\"Winner: T-C (Progressive)\")\n",
        "else:\n",
        "    print(\"Winner: T-B (Last Block)\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "id": "CXCW9qExG0dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing on the T-B Model"
      ],
      "metadata": {
        "id": "YFBo9EeJnUJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# --------------------------\n",
        "# Load Test Images\n",
        "# --------------------------\n",
        "TEST_DIR = '/kaggle/input/asl-alphabet/asl_alphabet_test/asl_alphabet_test'\n",
        "test_images = sorted([f for f in os.listdir(TEST_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "\n",
        "test_inputs = []\n",
        "true_labels = []\n",
        "\n",
        "for img_name in test_images:\n",
        "    img_path = os.path.join(TEST_DIR, img_name)\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    img = data_transforms['val'](img)\n",
        "    test_inputs.append(img)\n",
        "\n",
        "    # Extract true label from filename (e.g., \"A_test.jpg\" â†’ \"A\")\n",
        "    label_char = img_name.split('_')[0]\n",
        "    true_labels.append(classes.index(label_char))  # Convert to class index\n",
        "\n",
        "test_tensor = torch.stack(test_inputs).to(device)\n",
        "\n",
        "# --------------------------\n",
        "# Predict with Trained T-B Model\n",
        "# --------------------------\n",
        "trained_model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = trained_model(test_tensor)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "predicted_labels = preds.cpu().numpy()\n",
        "pred_classes = [classes[p] for p in predicted_labels]\n",
        "\n",
        "# --------------------------\n",
        "# Report Metrics\n",
        "# --------------------------\n",
        "acc, macro_f1 = calculate_metrics(predicted_labels, true_labels)\n",
        "print(\"\\nTest Accuracy:\", round(acc, 4))\n",
        "print(\"Test Macro-F1:\", round(macro_f1, 4))\n",
        "\n",
        "print(\"\\nPredicted Classes:\")\n",
        "for img_name, pred in zip(test_images, pred_classes):\n",
        "    print(f\"{img_name}: {pred}\")\n",
        "\n",
        "# --------------------------\n",
        "# Confusion Matrix\n",
        "# --------------------------\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "disp.plot(xticks_rotation=45, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix on 28-Image Test Set\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0Xge-hHpniI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the handmade signs on T-B"
      ],
      "metadata": {
        "id": "ErkhEVwG1ESc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyheif"
      ],
      "metadata": {
        "id": "0cP-_S517Alx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "iERCBZcf7k1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pyheif\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# PATH TO YOUR SHARED DRIVE DATASET\n",
        "# -----------------------------------------------------------\n",
        "DATA_DIR = \"/content/drive/Shared drives/DAEN 429 Final Project/Test Data (handtaken)\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# GET ALL .HEIC FILES\n",
        "# -----------------------------------------------------------\n",
        "image_files = sorted([\n",
        "    f for f in os.listdir(DATA_DIR)\n",
        "    if f.lower().endswith(\".heic\")\n",
        "])\n",
        "\n",
        "print(\"Found images:\", image_files)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# LOAD IMAGES + TRUE LABELS\n",
        "# -----------------------------------------------------------\n",
        "image_tensors = []\n",
        "true_labels = []\n",
        "\n",
        "for filename in image_files:\n",
        "    filepath = os.path.join(DATA_DIR, filename)\n",
        "\n",
        "    # -------------------------------------------\n",
        "    # FIX: Extract ONLY the first letter as label\n",
        "    # Examples:\n",
        "    #   \"C.HEIC\" â†’ C\n",
        "    #   \"C (1).HEIC\" â†’ C\n",
        "    #   \"G (2).HEIC\" â†’ G\n",
        "    # -------------------------------------------\n",
        "    label_char = filename[0].upper()\n",
        "\n",
        "    if label_char not in classes:\n",
        "        raise ValueError(f\"Label '{label_char}' not in classes list. Check class mapping.\")\n",
        "\n",
        "    true_label_idx = classes.index(label_char)\n",
        "    true_labels.append(true_label_idx)\n",
        "\n",
        "    # Load HEIC file â†’ PIL image\n",
        "    heif_file = pyheif.read(filepath)\n",
        "    image = Image.frombytes(\n",
        "        heif_file.mode,\n",
        "        heif_file.size,\n",
        "        heif_file.data,\n",
        "        \"raw\",\n",
        "        heif_file.mode,\n",
        "        heif_file.stride,\n",
        "    )\n",
        "\n",
        "    # Apply your validation transform\n",
        "    img_tensor = data_transforms[\"val\"](image)\n",
        "    image_tensors.append(img_tensor)\n",
        "\n",
        "# Stack into batch tensor\n",
        "X = torch.stack(image_tensors)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# MOVE TO DEVICE\n",
        "# -----------------------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "trained_model.to(device)\n",
        "X = X.to(device)\n",
        "y_true = torch.tensor(true_labels).to(device)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# RUN INFERENCE\n",
        "# -----------------------------------------------------------\n",
        "trained_model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = trained_model(X)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "pred_labels = preds.cpu().numpy()\n",
        "true_labels_np = y_true.cpu().numpy()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# METRICS\n",
        "# -----------------------------------------------------------\n",
        "acc, macro_f1 = calculate_metrics(pred_labels, true_labels_np)\n",
        "\n",
        "print(\"\\n=== RESULTS ON HAND-TAKEN HEIC DATA ===\")\n",
        "print(f\"Accuracy:  {acc:.4f}\")\n",
        "print(f\"Macro-F1:  {macro_f1:.4f}\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# CONFUSION MATRIX â€” FIXED FOR MISSING CLASSES\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Only include labels that appear in y_true OR pred_labels\n",
        "unique_label_indices = sorted(list(set(true_labels_np) | set(pred_labels)))\n",
        "\n",
        "# Map class indices to class names\n",
        "label_names = [classes[i] for i in unique_label_indices]\n",
        "\n",
        "# Build a filtered confusion matrix\n",
        "cm = confusion_matrix(true_labels_np, pred_labels, labels=unique_label_indices)\n",
        "\n",
        "# Display\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)\n",
        "disp.plot(xticks_rotation=45, cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix â€” Hand-Taken HEIC Dataset (Filtered)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "o6zApmMf1DR-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}